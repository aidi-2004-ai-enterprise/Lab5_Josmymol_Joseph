{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99b07a6",
   "metadata": {},
   "source": [
    "# Lab 4 – Binary Classification (Company Bankruptcy Prediction)\n",
    "\n",
    "**Dataset:**  \n",
    "- Taiwan Economic Journal, 1999–2009  \n",
    "- Imbalanced: ~6,819 samples, ~220 bankrupt (~3.2%)  \n",
    "- Source: [Kaggle Dataset](https://www.kaggle.com/datasets/fedesoriano/company-bankruptcy-prediction)  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Choosing Initial Models\n",
    "- **Benchmark:** Logistic Regression → interpretable, fast baseline, reference point  \n",
    "- **Additional Models:** Random Forest (non-linear, robust), XGBoost (high performance, imbalance handling)  \n",
    "- **Clustering?** No → unsupervised ≠ direct bankruptcy classification  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Pre-processing\n",
    "- Scale numeric features for LR (StandardScaler)  \n",
    "- Tree models don’t need scaling  \n",
    "- Median imputation for any missing values  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Handling Class Imbalance\n",
    "- Imbalance present (~3%)  \n",
    "- Decision: Use **class weights** + **stratified split**  \n",
    "- Avoid SMOTE → risk of overfitting synthetic points  \n",
    "- Undersampling → data loss, avoided  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Outlier Detection & Treatment\n",
    "- Remove only obvious errors (e.g., impossible values)  \n",
    "- Keep extreme but valid ratios → may signal risk  \n",
    "- IQR or z-score to flag issues  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Sampling Bias Check\n",
    "- PSI to compare train/test distributions  \n",
    "- Ensures fair evaluation and prevents false performance confidence  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Data Normalization\n",
    "- Apply StandardScaler for LR  \n",
    "- Skip for tree models  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Testing for Normality\n",
    "- Not required → models non-parametric or robust  \n",
    "- Optional log-transform for extreme skew  \n",
    "\n",
    "---\n",
    "\n",
    "## 8. Dimensionality Reduction (PCA)\n",
    "- **For:** reduce overfitting, speed  \n",
    "- **Against:** hides feature meaning  \n",
    "- Decision: No PCA → keep interpretability  \n",
    "\n",
    "---\n",
    "\n",
    "## 9. Feature Engineering\n",
    "- Dataset has ~96 ratio-based features already  \n",
    "- No new features created  \n",
    "\n",
    "---\n",
    "\n",
    "## 10. Multicollinearity\n",
    "- Check via VIF & correlation  \n",
    "- Drop high VIF features for LR (>10)  \n",
    "- Keep for trees (handled internally)  \n",
    "\n",
    "---\n",
    "\n",
    "## 11. Feature Selection\n",
    "- Lasso regression to remove weak features  \n",
    "- Validate with tree feature importance  \n",
    "\n",
    "---\n",
    "\n",
    "## 12. Hyperparameter Tuning\n",
    "- Random Search for efficiency → refine with Grid Search/Bayesian  \n",
    "- Apply to RF & XGBoost  \n",
    "\n",
    "---\n",
    "\n",
    "## 13. Cross-Validation\n",
    "- Stratified K-Fold (K=5) → preserve minority class ratio  \n",
    "\n",
    "---\n",
    "\n",
    "## 14. Evaluation Metrics\n",
    "- Evaluate `predict_proba` results  \n",
    "- ROC-AUC → overall discrimination  \n",
    "- PR-AUC → better for imbalance  \n",
    "- F1-score → balance precision & recall  \n",
    "- Avoid accuracy → misleading in imbalance  \n",
    "\n",
    "---\n",
    "\n",
    "## 15. Drift & Model Degradation\n",
    "- PSI between train & test → detect data drift early  \n",
    "- Prevents performance drop in production  \n",
    "\n",
    "---\n",
    "\n",
    "## 16. Interpretability\n",
    "- SHAP values for feature-level explanation  \n",
    "- Useful for regulatory review & stakeholder trust  \n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| Area                      | Decision & Why |\n",
    "|---------------------------|----------------|\n",
    "| Benchmark model           | Logistic Regression — interpretable baseline |\n",
    "| Additional models         | Random Forest, XGBoost — strong non-linear performance |\n",
    "| Clustering?               | No — unsupervised not suitable |\n",
    "| Preprocessing             | Scale for LR; impute missing values |\n",
    "| Imbalance handling        | Class weights + stratified split |\n",
    "| Outliers                  | Remove only errors; keep informative extremes |\n",
    "| Sampling bias check       | PSI for train/test alignment |\n",
    "| Normalization             | Only for LR; skip for trees |\n",
    "| Normality testing         | Not required; optional log-transform |\n",
    "| PCA                       | No — keep interpretability |\n",
    "| Feature engineering       | None — dataset comprehensive |\n",
    "| Multicollinearity         | Drop per VIF for LR; trees tolerate |\n",
    "| Feature selection         | Lasso + tree importance |\n",
    "| Hyperparameter tuning     | Random Search → Grid/Bayesian |\n",
    "| Cross-validation          | Stratified K-Fold |\n",
    "| Metrics                   | ROC-AUC, PR-AUC, F1 |\n",
    "| Drift checking            | PSI between train/test |\n",
    "| Explainability            | SHAP for transparency |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19816073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josmy\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bankrupt?   ROA(C) before interest and depreciation before interest  \\\n",
      "0          1                                           0.370594          \n",
      "1          1                                           0.464291          \n",
      "2          1                                           0.426071          \n",
      "3          1                                           0.399844          \n",
      "4          1                                           0.465022          \n",
      "\n",
      "    ROA(A) before interest and % after tax  \\\n",
      "0                                 0.424389   \n",
      "1                                 0.538214   \n",
      "2                                 0.499019   \n",
      "3                                 0.451265   \n",
      "4                                 0.538432   \n",
      "\n",
      "    ROA(B) before interest and depreciation after tax  \\\n",
      "0                                           0.405750    \n",
      "1                                           0.516730    \n",
      "2                                           0.472295    \n",
      "3                                           0.457733    \n",
      "4                                           0.522298    \n",
      "\n",
      "    Operating Gross Margin   Realized Sales Gross Margin  \\\n",
      "0                 0.601457                      0.601457   \n",
      "1                 0.610235                      0.610235   \n",
      "2                 0.601450                      0.601364   \n",
      "3                 0.583541                      0.583541   \n",
      "4                 0.598783                      0.598783   \n",
      "\n",
      "    Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
      "0                0.998969                    0.796887   \n",
      "1                0.998946                    0.797380   \n",
      "2                0.998857                    0.796403   \n",
      "3                0.998700                    0.796967   \n",
      "4                0.998973                    0.797366   \n",
      "\n",
      "    After-tax net Interest Rate   Non-industry income and expenditure/revenue  \\\n",
      "0                      0.808809                                      0.302646   \n",
      "1                      0.809301                                      0.303556   \n",
      "2                      0.808388                                      0.302035   \n",
      "3                      0.808966                                      0.303350   \n",
      "4                      0.809304                                      0.303475   \n",
      "\n",
      "   ...   Net Income to Total Assets   Total assets to GNP price  \\\n",
      "0  ...                     0.716845                    0.009219   \n",
      "1  ...                     0.795297                    0.008323   \n",
      "2  ...                     0.774670                    0.040003   \n",
      "3  ...                     0.739555                    0.003252   \n",
      "4  ...                     0.795016                    0.003878   \n",
      "\n",
      "    No-credit Interval   Gross Profit to Sales  \\\n",
      "0             0.622879                0.601453   \n",
      "1             0.623652                0.610237   \n",
      "2             0.623841                0.601449   \n",
      "3             0.622929                0.583538   \n",
      "4             0.623521                0.598782   \n",
      "\n",
      "    Net Income to Stockholder's Equity   Liability to Equity  \\\n",
      "0                             0.827890              0.290202   \n",
      "1                             0.839969              0.283846   \n",
      "2                             0.836774              0.290189   \n",
      "3                             0.834697              0.281721   \n",
      "4                             0.839973              0.278514   \n",
      "\n",
      "    Degree of Financial Leverage (DFL)  \\\n",
      "0                             0.026601   \n",
      "1                             0.264577   \n",
      "2                             0.026555   \n",
      "3                             0.026697   \n",
      "4                             0.024752   \n",
      "\n",
      "    Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
      "0                                           0.564050                   1   \n",
      "1                                           0.570175                   1   \n",
      "2                                           0.563706                   1   \n",
      "3                                           0.564663                   1   \n",
      "4                                           0.575617                   1   \n",
      "\n",
      "    Equity to Liability  \n",
      "0              0.016469  \n",
      "1              0.020794  \n",
      "2              0.016474  \n",
      "3              0.023982  \n",
      "4              0.035490  \n",
      "\n",
      "[5 rows x 96 columns]\n",
      "Accuracy: 0.967741935483871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1313\n",
      "           1       0.82      0.18      0.29        51\n",
      "\n",
      "    accuracy                           0.97      1364\n",
      "   macro avg       0.89      0.59      0.64      1364\n",
      "weighted avg       0.96      0.97      0.96      1364\n",
      "\n",
      "PSI for  ROA(C) before interest and depreciation before interest: 0.008606113549994972\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Define features and target\n",
    "# NOTE: Change 'Bankrupt?' to your target column name in the CSV\n",
    "X = df.drop(columns=[\"Bankrupt?\"])\n",
    "y = df[\"Bankrupt?\"]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy and report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to calculate PSI\n",
    "def calculate_psi(expected, actual, buckets=10):\n",
    "    def scale_range(input_array, min_val, max_val):\n",
    "        input_array = np.clip(input_array, min_val, max_val)\n",
    "        return input_array\n",
    "\n",
    "    breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "    breakpoints = np.percentile(expected, breakpoints)\n",
    "\n",
    "    expected_percents = np.histogram(expected, bins=breakpoints)[0] / len(expected)\n",
    "    actual_percents = np.histogram(actual, bins=breakpoints)[0] / len(actual)\n",
    "\n",
    "    psi_value = np.sum(\n",
    "        (expected_percents - actual_percents)\n",
    "        * np.log(expected_percents / actual_percents)\n",
    "    )\n",
    "    return psi_value\n",
    "\n",
    "# Example PSI calculation for first feature\n",
    "first_feature = X.columns[0]\n",
    "psi_score = calculate_psi(X_train[first_feature], X_test[first_feature])\n",
    "print(f\"PSI for {first_feature}: {psi_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbc07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
